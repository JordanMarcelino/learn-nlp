{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spacy Vs NLTK\n",
    "\n",
    "Spacy and NLTK are language processing tools that allows us to extract information from a text.\n",
    "\n",
    "Here's the difference between both of them\n",
    "\n",
    "<table>\n",
    "    <thead>\n",
    "        <th>Spacy</th>\n",
    "        <th>NLTK</th>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td>Object Oriented</td>\n",
    "            <td>Mainly a string processing library</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>It gives the best and most effective algorithm for a given task. If you care about the end result, Spacy is the best option (Best for production)</td>\n",
    "            <td>It offer access to a lot of algorithm. If you care about specific algorithm and customization, go for NLTK (Best for research)</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>User friendly</td>\n",
    "            <td>User friendly too but less user friendly compared to Spacy</td>\n",
    "        </tr>\n",
    "    </tbody>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spacy Demo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Dr. Strange likes Indonesian food a lot. He likes nasi goreng, ayam bakar, pempek, etc. He's planning to go to Indonesian one day\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Dr. Strange likes Indonesian food a lot.,\n",
       " He likes nasi goreng, ayam bakar, pempek, etc.,\n",
       " He's planning to go to Indonesian one day]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split by sentences\n",
    "sentences = []\n",
    "for sent in nlp(text).sents:\n",
    "    sentences.append(sent)\n",
    "sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Dr.,\n",
       " Strange,\n",
       " likes,\n",
       " Indonesian,\n",
       " food,\n",
       " a,\n",
       " lot,\n",
       " .,\n",
       " He,\n",
       " likes,\n",
       " nasi,\n",
       " goreng,\n",
       " ,,\n",
       " ayam,\n",
       " bakar,\n",
       " ,,\n",
       " pempek,\n",
       " ,,\n",
       " etc,\n",
       " .,\n",
       " He,\n",
       " 's,\n",
       " planning,\n",
       " to,\n",
       " go,\n",
       " to,\n",
       " Indonesian,\n",
       " one,\n",
       " day]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split by words\n",
    "words = []\n",
    "for sent in nlp(text).sents:\n",
    "    for word in sent:\n",
    "        words.append(word)\n",
    "words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLTK Demo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "nltk.download(\"punkt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dr.',\n",
       " 'Strange likes Indonesian food a lot.',\n",
       " 'He likes nasi goreng, ayam bakar, pempek, etc.',\n",
       " \"He's planning to go to Indonesian one day\"]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dr',\n",
       " '.',\n",
       " 'Strange',\n",
       " 'likes',\n",
       " 'Indonesian',\n",
       " 'food',\n",
       " 'a',\n",
       " 'lot',\n",
       " '.',\n",
       " 'He',\n",
       " 'likes',\n",
       " 'nasi',\n",
       " 'goreng',\n",
       " ',',\n",
       " 'ayam',\n",
       " 'bakar',\n",
       " ',',\n",
       " 'pempek',\n",
       " ',',\n",
       " 'etc',\n",
       " '.',\n",
       " 'He',\n",
       " \"'s\",\n",
       " 'planning',\n",
       " 'to',\n",
       " 'go',\n",
       " 'to',\n",
       " 'Indonesian',\n",
       " 'one',\n",
       " 'day']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
