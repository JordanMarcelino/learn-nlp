{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XFT4zbqFwRmr"
   },
   "source": [
    "### **Bag of n_grams: Exercise**\n",
    "\n",
    "-   In this Exercise, you are going to classify whether a given movie review is **positive or negative**.\n",
    "\n",
    "-   You will use a Bag of n-grams to pre-process the text and apply different classification algorithms.\n",
    "\n",
    "-   Sklearn CountVectorizer has the inbuilt implementations for Bag of Words.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GBcs8GQb0C9_"
   },
   "source": [
    "### **About Data: IMDB Dataset**\n",
    "\n",
    "Credits: https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews?resource=download\n",
    "\n",
    "-   This data consists of two columns. - review - sentiment\n",
    "-   Reviews are the statements given by users after watching the movie.\n",
    "-   sentiment feature tells whether the given review is positive or negative.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "KiYilX-lv_Vm",
    "outputId": "3a7bcc05-8e94-4d3d-c2a7-89d74f2b8202"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44860</th>\n",
       "      <td>A broke would be screenwriter and his would be...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47924</th>\n",
       "      <td>Tedious girls-at-reform-school flick, which pl...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44024</th>\n",
       "      <td>I have a little hobby of finding really cool p...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16077</th>\n",
       "      <td>It's proof that movie makers and their financi...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47091</th>\n",
       "      <td>I remember seeing this movie a long time ago o...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "44860  A broke would be screenwriter and his would be...  negative\n",
       "47924  Tedious girls-at-reform-school flick, which pl...  negative\n",
       "44024  I have a little hobby of finding really cool p...  positive\n",
       "16077  It's proof that movie makers and their financi...  negative\n",
       "47091  I remember seeing this movie a long time ago o...  negative"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import pandas library\n",
    "import pandas as pd\n",
    "\n",
    "# read the dataset and store it in a variable df\n",
    "df = pd.read_csv(\"IMDB dataset.csv\")\n",
    "df = df.sample(5000)\n",
    "\n",
    "# print the shape of dataframe\n",
    "print(df.shape)\n",
    "\n",
    "\n",
    "# print top 5 rows\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N59dp0n1v_XU",
    "outputId": "3a438088-ff3f-4f57-9fbf-565b96693f02"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "negative    2518\n",
       "positive    2482\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the distribution of labels\n",
    "df.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "Zr-vBY7xv_a3",
    "outputId": "1c447daa-237a-48c0-9b3f-3342f63093e2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44860</th>\n",
       "      <td>A broke would be screenwriter and his would be...</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47924</th>\n",
       "      <td>Tedious girls-at-reform-school flick, which pl...</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44024</th>\n",
       "      <td>I have a little hobby of finding really cool p...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16077</th>\n",
       "      <td>It's proof that movie makers and their financi...</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47091</th>\n",
       "      <td>I remember seeing this movie a long time ago o...</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment  label_num\n",
       "44860  A broke would be screenwriter and his would be...  negative          1\n",
       "47924  Tedious girls-at-reform-school flick, which pl...  negative          1\n",
       "44024  I have a little hobby of finding really cool p...  positive          0\n",
       "16077  It's proof that movie makers and their financi...  negative          1\n",
       "47091  I remember seeing this movie a long time ago o...  negative          1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add the new column \"label_num\" which gives a unique number to each of these labels\n",
    "df[\"label_num\"] = df[\"sentiment\"].map({\"positive\": 0, \"negative\": 1})\n",
    "\n",
    "# check the results with top 5 rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ev3bWDnA3tM-"
   },
   "source": [
    "### **Modelling without Pre-processing Text data**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "hs94POE23Zjd"
   },
   "outputs": [],
   "source": [
    "# import train-test-split from sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Do the 'train-test' splitting with test size of 20% with random state of 2022 and stratify sampling too\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[\"review\"],\n",
    "    df[\"label_num\"],\n",
    "    test_size=0.2,\n",
    "    random_state=2024,\n",
    "    stratify=df[\"label_num\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4I4S1PJG3ZlO",
    "outputId": "0d9865bd-48b9-4def-cfed-c740d6e02f8f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4000,), (1000,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the shapes of X_train and X_test\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x2sO9uck4ILs"
   },
   "source": [
    "**Attempt 1** :\n",
    "\n",
    "1. using sklearn pipeline module create a classification pipeline to classify the Data.\n",
    "\n",
    "**Note:**\n",
    "\n",
    "-   using CountVectorizer with unigram, bigram, and trigrams.\n",
    "-   use KNN as the classifier with n_neighbors of 10 and metric as 'euclidean' distance.\n",
    "-   print the classification report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LLs6pmXE3Zou",
    "outputId": "1bbb4bf1-0b1e-4c5e-f751-fa4b331e772f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.78      0.64       496\n",
      "           1       0.63      0.37      0.46       504\n",
      "\n",
      "    accuracy                           0.57      1000\n",
      "   macro avg       0.59      0.57      0.55      1000\n",
      "weighted avg       0.59      0.57      0.55      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 1. create a pipeline object\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"n_gram\", CountVectorizer(ngram_range=(1, 3))),\n",
    "        (\"classifier\", KNeighborsClassifier(n_neighbors=10, metric=\"euclidean\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# 2. fit with X_train and y_train\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# 3. get the predictions for X_test and store it in y_pred\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "\n",
    "# 4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OU0g90Ra7BTW"
   },
   "source": [
    "**Attempt 2** :\n",
    "\n",
    "1. using the sklearn pipeline module create a classification pipeline to classify the Data.\n",
    "\n",
    "**Note:**\n",
    "\n",
    "-   using CountVectorizer with unigram, bigram, and trigrams.\n",
    "-   use **KNN** as the classifier with n_neighbors of 10 and metric as 'cosine' distance.\n",
    "-   print the classification report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eEsLSrIC3Zqf",
    "outputId": "b0354edc-1d3f-401b-c1ed-dd0cb7b769b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.82      0.67       496\n",
      "           1       0.69      0.39      0.50       504\n",
      "\n",
      "    accuracy                           0.60      1000\n",
      "   macro avg       0.63      0.61      0.59      1000\n",
      "weighted avg       0.63      0.60      0.59      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. create a pipeline object\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"n_gram\", CountVectorizer(ngram_range=(1, 3))),\n",
    "        (\"classifier\", KNeighborsClassifier(n_neighbors=10, metric=\"cosine\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# 2. fit with X_train and y_train\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# 3. get the predictions for X_test and store it in y_pred\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "\n",
    "# 4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kl5zoCbE8jds"
   },
   "source": [
    "**Attempt 3** :\n",
    "\n",
    "1. using the sklearn pipeline module create a classification pipeline to classify the Data.\n",
    "\n",
    "**Note:**\n",
    "\n",
    "-   using CountVectorizer with only trigrams.\n",
    "-   use **RandomForest** as the classifier.\n",
    "-   print the classification report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4bywjvZyv_ga",
    "outputId": "e2c93b51-8508-4c5a-b0ca-54e34ebe5075"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.92      0.74       496\n",
      "           1       0.85      0.43      0.57       504\n",
      "\n",
      "    accuracy                           0.68      1000\n",
      "   macro avg       0.73      0.68      0.66      1000\n",
      "weighted avg       0.73      0.68      0.66      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. create a pipeline object\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"n_gram\", CountVectorizer(ngram_range=(3, 3))),\n",
    "        (\"classifier\", RandomForestClassifier()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# 2. fit with X_train and y_train\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# 3. get the predictions for X_test and store it in y_pred\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "\n",
    "# 4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RMeeE5zB8tZz"
   },
   "source": [
    "**Attempt 4** :\n",
    "\n",
    "1. using the sklearn pipeline module create a classification pipeline to classify the Data.\n",
    "\n",
    "**Note:**\n",
    "\n",
    "-   using CountVectorizer with both unigram and bigrams.\n",
    "-   use **Multinomial Naive Bayes** as the classifier with an alpha value of 0.75.\n",
    "-   print the classification report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9cP_zluNwBjS",
    "outputId": "108dd86a-5938-4040-9813-00b82d393ad1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.81      0.83       496\n",
      "           1       0.82      0.86      0.84       504\n",
      "\n",
      "    accuracy                           0.83      1000\n",
      "   macro avg       0.84      0.83      0.83      1000\n",
      "weighted avg       0.84      0.83      0.83      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. create a pipeline object\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"n_gram\", CountVectorizer(ngram_range=(1, 2))),\n",
    "        (\"classifier\", MultinomialNB(alpha=0.75)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# 2. fit with X_train and y_train\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# 3. get the predictions for X_test and store it in y_pred\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "\n",
    "# 4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IoFBbMga9tPB"
   },
   "source": [
    "<h3>Use text pre-processing to remove stop words, punctuations and apply lemmatization </h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "R14_wUhGjqj5"
   },
   "outputs": [],
   "source": [
    "# use this utility function to get the preprocessed text data\n",
    "\n",
    "import spacy\n",
    "\n",
    "# load english language model and create nlp object from it\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "\n",
    "def preprocess(text):\n",
    "    # remove stop words and lemmatize the text\n",
    "    doc = nlp(text)\n",
    "    filtered_tokens = []\n",
    "    for token in doc:\n",
    "        if token.is_stop or token.is_punct:\n",
    "            continue\n",
    "        filtered_tokens.append(token.lemma_)\n",
    "\n",
    "    return \" \".join(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "JIKvTbl9jql0"
   },
   "outputs": [],
   "source": [
    "# create a new column \"preprocessed_txt\" and use the utility function above to get the clean data\n",
    "# this will take some time, please be patient\n",
    "df[\"preprocessed_txt\"] = df[\"review\"].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "0O-uZncOjqpG",
    "outputId": "02d45596-aa7a-449d-dbba-3afd2bd8908b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label_num</th>\n",
       "      <th>preprocessed_txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44860</th>\n",
       "      <td>A broke would be screenwriter and his would be...</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "      <td>broke screenwriter agent Tom Wood Arye Gross f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47924</th>\n",
       "      <td>Tedious girls-at-reform-school flick, which pl...</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "      <td>tedious girl reform school flick play somewhat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44024</th>\n",
       "      <td>I have a little hobby of finding really cool p...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>little hobby find cool pic pretty unknown -and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16077</th>\n",
       "      <td>It's proof that movie makers and their financi...</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "      <td>proof movie maker financier treat audience con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47091</th>\n",
       "      <td>I remember seeing this movie a long time ago o...</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "      <td>remember see movie long time ago television re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment  label_num  \\\n",
       "44860  A broke would be screenwriter and his would be...  negative          1   \n",
       "47924  Tedious girls-at-reform-school flick, which pl...  negative          1   \n",
       "44024  I have a little hobby of finding really cool p...  positive          0   \n",
       "16077  It's proof that movie makers and their financi...  negative          1   \n",
       "47091  I remember seeing this movie a long time ago o...  negative          1   \n",
       "\n",
       "                                        preprocessed_txt  \n",
       "44860  broke screenwriter agent Tom Wood Arye Gross f...  \n",
       "47924  tedious girl reform school flick play somewhat...  \n",
       "44024  little hobby find cool pic pretty unknown -and...  \n",
       "16077  proof movie maker financier treat audience con...  \n",
       "47091  remember see movie long time ago television re...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the top 5 rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IMVuYaYM-giF"
   },
   "source": [
    "**Build a model with pre processed text**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "D25BcI45jqrE"
   },
   "outputs": [],
   "source": [
    "# Do the 'train-test' splitting with test size of 20% with random state of 2022 and stratify sampling too\n",
    "# Note: Make sure to use only the \"preprocessed_txt\" column for splitting\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[\"preprocessed_txt\"],\n",
    "    df[\"label_num\"],\n",
    "    test_size=0.2,\n",
    "    random_state=2024,\n",
    "    stratify=df[\"label_num\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZOh36PXR-nR_"
   },
   "source": [
    "**Let's check the scores with our best model till now**\n",
    "\n",
    "-   Random Forest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YbfpQ5-kDgMt"
   },
   "source": [
    "**Attempt1** :\n",
    "\n",
    "1. using the sklearn pipeline module create a classification pipeline to classify the Data.\n",
    "\n",
    "**Note:**\n",
    "\n",
    "-   using CountVectorizer with only trigrams.\n",
    "-   use **RandomForest** as the classifier.\n",
    "-   print the classification report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BGQusE2rjquN",
    "outputId": "d1b83f99-0983-4feb-e24e-e3f9f2e09632"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.95      0.69       496\n",
      "           1       0.80      0.18      0.30       504\n",
      "\n",
      "    accuracy                           0.56      1000\n",
      "   macro avg       0.67      0.57      0.49      1000\n",
      "weighted avg       0.67      0.56      0.49      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. create a pipeline object\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"n_gram\", CountVectorizer(ngram_range=(3, 3))),\n",
    "        (\"classifier\", RandomForestClassifier()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# 2. fit with X_train and y_train\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# 3. get the predictions for X_test and store it in y_pred\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "\n",
    "# 4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GB78pcAPEFQZ"
   },
   "source": [
    "**Attempt2** :\n",
    "\n",
    "1. using the sklearn pipeline module create a classification pipeline to classify the Data.\n",
    "\n",
    "**Note:**\n",
    "\n",
    "-   using CountVectorizer with unigram, Bigram, and trigrams.\n",
    "-   use **RandomForest** as the classifier.\n",
    "-   print the classification report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rpwvD1mvjqvx",
    "outputId": "bbee2e0b-98da-4ae0-a480-259e0de8fa29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.87      0.82       496\n",
      "           1       0.86      0.75      0.80       504\n",
      "\n",
      "    accuracy                           0.81      1000\n",
      "   macro avg       0.82      0.81      0.81      1000\n",
      "weighted avg       0.82      0.81      0.81      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. create a pipeline object\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"n_gram\", CountVectorizer(ngram_range=(1, 3))),\n",
    "        (\"classifier\", RandomForestClassifier()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# 2. fit with X_train and y_train\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# 3. get the predictions for X_test and store it in y_pred\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "\n",
    "# 4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.78      0.80       496\n",
      "           1       0.79      0.84      0.82       504\n",
      "\n",
      "    accuracy                           0.81      1000\n",
      "   macro avg       0.81      0.81      0.81      1000\n",
      "weighted avg       0.81      0.81      0.81      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. create a pipeline object\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"n_gram\", CountVectorizer(ngram_range=(1, 2))),\n",
    "        (\"classifier\", MultinomialNB(alpha=0.75)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# 2. fit with X_train and y_train\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# 3. get the predictions for X_test and store it in y_pred\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "\n",
    "# 4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 460
    },
    "id": "SLT0vKGRHAMF",
    "outputId": "540746d1-2dec-4585-918b-c4afba111e26"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[385, 111],\n",
       "       [ 80, 424]], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# finally print the confusion matrix for the best model\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "bag_of_n_grams_exercise.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
